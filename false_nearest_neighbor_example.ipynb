{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Fourier_Power_Spectrum\n",
    "import plotting_utilities\n",
    "import save_utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import time \n",
    "from tqdm.notebook import tqdm \n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Current</th>\n",
       "      <th>Voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.179686</td>\n",
       "      <td>-64.490236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.092775</td>\n",
       "      <td>-64.337648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-7.841795</td>\n",
       "      <td>-64.581788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.092775</td>\n",
       "      <td>-64.307130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.958983</td>\n",
       "      <td>-64.429200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time   Current    Voltage\n",
       "0     0 -4.179686 -64.490236\n",
       "1     1  0.092775 -64.337648\n",
       "2     2 -7.841795 -64.581788\n",
       "3     3  0.092775 -64.307130\n",
       "4     4 -2.958983 -64.429200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get target data (Lilac 114, Neuron 1, epoch_1.txt)\n",
    "# Column1: Current, Column2: Voltage\n",
    "try:\n",
    "    lilac_114_1_1 = pd.read_csv('./Data2022-50KhZ/7-7-2022/Lilac 114/Neuron 1/epoch_1.txt', delimiter='\\t', header=None)\n",
    "except: \n",
    "    lilac_114_1_1 = pd.read_csv('./Data2022-50KhZ/Lilac 114/Neuron 1/epoch_1.txt', delimiter='\\t', header=None)\n",
    "lilac_114_1_1.reset_index(inplace=True)\n",
    "lilac_114_1_1.columns = ['Time', 'Current', 'Voltage']\n",
    "lilac_114_1_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to visualize \n",
    "# figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "# ax1.set_title(\"Time vs Current\")\n",
    "# ax1.plot(lilac_114_1_1.Time, lilac_114_1_1.Current)\n",
    "# ax2.set_title(\"Time vs Voltage\")\n",
    "# ax2.plot(lilac_114_1_1.Time, lilac_114_1_1.Voltage)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Nearest Neighbor Algorithm to Determine Time Delay Vector Dimensionality \n",
    "\n",
    "##### Procedure\n",
    "1. Define the target time delay vector (regressor) to run FNN on, and then generate time delay vectors for each time step of the voltage data: $\\psi_{l}(t) = [y(k-\\tau), ..., y(k-l \\tau)] \\text{ where } l\\in[0, D]$.\n",
    "2. For each points, identify the closest point in time delay space (we can search within a window, or through out all points), i.e. minimize this distance: $d = ||\\psi_{l}(t_1) - \\psi_{l}(t_2)||$.\n",
    "3. The inequality below determines if two closest points are \"true neighbors\" or \"false neighbors\": $$\\frac{|y(t)-y(j)|}{||\\psi_l(t) - \\psi_l (j)||_2} \\leq R$$\n",
    "    - If inequality is true, then the two points are true neighbors. \n",
    "    - If inequality is false, then the two points are false neighbors. \n",
    "4. Repeat step 3 for all points in the dataset, and then record the percentage of points in datasets with false nearest neighbors, giving the current time delay vector dimension. \n",
    "5. Increase the value of D until the percentage of false nearest neighbors is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Create time delay vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: change window to random sampling data from entire dataset, or start with every 1000th data points and move down on the skip size \n",
    "\n",
    "# TODO: save result as txt file; rows: D values, column: FNN ratio,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 0.9850034713745117.\n"
     ]
    }
   ],
   "source": [
    "# define tau (user provided), distance ratio threshold R (user defined hyperparameter), and range of D to search over (trainable parameter)\n",
    "tau = 5\n",
    "R_ratio = 10 # TODO: Investigate optimal value of R; 10 is suggested by the original paper \n",
    "D_arr = np.array([1, 2, 4, 6, 8, 10, 12, 15, 18, 20])  \n",
    "\n",
    "# create the time delay vectors for each data points with each of the D values\n",
    "original_data = lilac_114_1_1.to_numpy()\n",
    "T = original_data[:, 0].astype(np.int64)\n",
    "I = original_data[:, 1].astype(np.float64)\n",
    "V_0 = original_data[:, 2].astype(np.float64).reshape((len(T), 1)) # voltage at 0*tau\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "time_delay_datasets = []\n",
    "for d in D_arr:\n",
    "    V_s = np.dstack([np.concatenate([V_0[-i*tau:, :], V_0[:-i*tau, :]], axis=0) for i in range(d+1)])[:, 0, :]\n",
    "    time_delay_datasets.append(V_s)\n",
    "end = time.time()\n",
    "print(f\"This took {end-start}.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For D=1, the shape of the dataset is (750000, 2)\n",
      "For D=2, the shape of the dataset is (750000, 3)\n",
      "For D=4, the shape of the dataset is (750000, 5)\n",
      "For D=6, the shape of the dataset is (750000, 7)\n",
      "For D=8, the shape of the dataset is (750000, 9)\n",
      "For D=10, the shape of the dataset is (750000, 11)\n",
      "For D=12, the shape of the dataset is (750000, 13)\n",
      "For D=15, the shape of the dataset is (750000, 16)\n",
      "For D=18, the shape of the dataset is (750000, 19)\n",
      "For D=20, the shape of the dataset is (750000, 21)\n"
     ]
    }
   ],
   "source": [
    "# check the datasets shapes\n",
    "for D_index in range(len(D_arr)): \n",
    "    print(f\"For D={D_arr[D_index]}, the shape of the dataset is {time_delay_datasets[D_index].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-64.49023555, -54.60254001],\n",
       "       [-64.33764765, -54.4804697 ],\n",
       "       [-64.58178828, -54.4804697 ],\n",
       "       [-64.30713008, -54.32788181],\n",
       "       [-64.42920039, -54.57202244],\n",
       "       [-64.52075313, -64.49023555],\n",
       "       [-64.2766125 , -64.33764765],\n",
       "       [-64.36816523, -64.58178828],\n",
       "       [-64.24609492, -64.30713008],\n",
       "       [-64.64282344, -64.42920039],\n",
       "       [-64.30713008, -64.52075313],\n",
       "       [-64.2766125 , -64.2766125 ],\n",
       "       [-64.58178828, -64.36816523],\n",
       "       [-64.30713008, -64.24609492],\n",
       "       [-64.55127071, -64.64282344],\n",
       "       [-64.33764765, -64.30713008],\n",
       "       [-64.67334102, -64.2766125 ],\n",
       "       [-64.52075313, -64.58178828],\n",
       "       [-64.24609492, -64.30713008],\n",
       "       [-64.58178828, -64.55127071]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data \n",
    "\"\"\"\n",
    "Every second element should match up with the first element of the Dth row down the line, i.e. array[0, 1] == array[D, 1] \n",
    "\"\"\"\n",
    "time_delay_datasets[0][:20] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Calculate distance between points, and for each point, find its closest point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data from array to tensor for faster calculation \n",
    "torch.device('cuda')\n",
    "\n",
    "time_delay_datasets = [torch.tensor(arr) for arr in time_delay_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of find the nearest point for all available points in the dataset takes 2 hours (projected) for each dataset, lets try this with a smaller window=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f442f8b72c45d692ce36effb318a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xueze\\AppData\\Local\\Temp\\ipykernel_23264\\3244217045.py:43: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  result_data = np.array(result_data)\n",
      "C:\\Users\\xueze\\AppData\\Local\\Temp\\ipykernel_23264\\3244217045.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result_data = np.array(result_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[tensor([-64.4902, -54.6025], dtype=torch.float64),\n",
       "         tensor([-64.4292, -54.5720], dtype=torch.float64)]], dtype=object),\n",
       " array([[0, 4]], dtype=int64))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the min distance result (test) - window=200 will run for 20 mins\n",
    "\"\"\"\n",
    "TODO: I am trying to fix the issue with NN being to close to the target\n",
    "\"\"\"\n",
    "\n",
    "test_data = time_delay_datasets[0]\n",
    "\n",
    "def generate_min_dist_datapoints(data, window=1000): \n",
    "    result_data, result_index = [], []\n",
    "    for i in tqdm(range(len(data))): \n",
    "\n",
    "        # create a window of data point to search over \n",
    "        # save the starting index and the ending index of our window as reference\n",
    "        start_index, end_index = max(i-window, 0), min(len(data), i+window)\n",
    "\n",
    "        # exclude the target point from the window\n",
    "        search_window = torch.cat([\n",
    "            data[start_index:i], \n",
    "            data[i+1:end_index]\n",
    "        ]) \n",
    "        # print(search_window)\n",
    "\n",
    "        # run the distance calculation and find the closest point and their indices\n",
    "        distance = torch.norm(search_window - data[i], dim=1)\n",
    "        # print(search_window - data[i])\n",
    "        # print(torch.norm(search_window - data[i], dim=1))\n",
    "        min_distance_index = torch.argmin(distance) # index of minimum distance point inside the window of datapoints \n",
    "        print(min_distance_index)\n",
    "        min_distance_pair_data = [data[i].data, search_window[min_distance_index].data]\n",
    "\n",
    "        # find the real index in respect to the entire dataset \n",
    "        real_min_distance_index = start_index + min_distance_index + 1 if start_index + min_distance_index >= i else start_index + min_distance_index\n",
    "        min_distance_pair_index = [i, real_min_distance_index.data]\n",
    "\n",
    "        # save the closest point's index\n",
    "        # this is the k and j: index of the first and second data points \n",
    "        result_data.append(min_distance_pair_data)\n",
    "        result_index.append(min_distance_pair_index)\n",
    "\n",
    "        # early stopping for testing purposes \n",
    "        if i == 0: \n",
    "            break\n",
    "    \n",
    "    # convert the list to numpy array \n",
    "    result_data = np.array(result_data)\n",
    "    result_index = np.array(result_index)\n",
    "\n",
    "    \n",
    "    # print(\"Saving results...\")\n",
    "    # np.save(f'min_datapairs_D={test_data.shape[1]}_window={window}_datapoints', result_data)\n",
    "    # np.save(f'min_datapairs_D={test_data.shape[1]}_window={window}_location', result_index)\n",
    "    # print(\"Results saved.\")\n",
    "    return result_data, result_index\n",
    "\n",
    "# print(test_data)\n",
    "test_data, test_index = generate_min_dist_datapoints(test_data)\n",
    "test_data, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06823938072142638"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.norm(test_data[0].shape)\n",
    "np.linalg.norm(np.diff(test_data[0])[0])\n",
    "# np.diff(test_data[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Count the number of False Nearest Neighbors and True Nearest Neighbors in the current setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from npy file \n",
    "D_2_index, D_2_data = np.load(\".\\FNN\\min_datapairs_D=20_window=1000_location.npy\"), np.load(\".\\FNN\\min_datapairs_D=20_window=1000_datapoints.npy\")\n",
    "D_2_index = D_2_index.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-64.490234 -64.30713  -64.45972  -64.45972  -64.490234 -64.58179\n",
      " -64.82593  -64.64282  -64.55127  -64.33765  -64.55127  -64.45972\n",
      " -64.4292   -64.55127  -64.67334  -64.612305 -64.55127  -64.612305\n",
      " -64.734375 -64.79541  -64.76489 ] [-64.490234 -64.368164 -64.52075  -64.64282  -64.58179  -64.52075\n",
      " -64.64282  -64.64282  -64.55127  -64.39868  -64.490234 -64.490234\n",
      " -64.52075  -64.55127  -64.82593  -64.76489  -64.52075  -64.4292\n",
      " -64.76489  -64.856445 -64.58179 ] 0.4717903\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\DDF-HVC-CM-Neurons\\false_nearest_neighbor_example.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/DDF-HVC-CM-Neurons/false_nearest_neighbor_example.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m fnn \u001b[39m/\u001b[39m (fnn\u001b[39m+\u001b[39mtnn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/DDF-HVC-CM-Neurons/false_nearest_neighbor_example.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# test the function on the first dataset    \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GitHub/DDF-HVC-CM-Neurons/false_nearest_neighbor_example.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m fnn_ratio \u001b[39m=\u001b[39m count_fnn(D_2_index, D_2_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/DDF-HVC-CM-Neurons/false_nearest_neighbor_example.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m fnn_ratio\n",
      "\u001b[1;32md:\\GitHub\\DDF-HVC-CM-Neurons\\false_nearest_neighbor_example.ipynb Cell 16\u001b[0m in \u001b[0;36mcount_fnn\u001b[1;34m(index, dataset, threshold_R)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/DDF-HVC-CM-Neurons/false_nearest_neighbor_example.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39melse\u001b[39;00m: \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/DDF-HVC-CM-Neurons/false_nearest_neighbor_example.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         tnn \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GitHub/DDF-HVC-CM-Neurons/false_nearest_neighbor_example.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m fnn \u001b[39m/\u001b[39;49m (fnn\u001b[39m+\u001b[39;49mtnn)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "def count_fnn(index, dataset, threshold_R=30):\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    dataset: A dataset should contain all the points and their closest point in pairs; example [(point_vec1, point_vec2)_1, (point_vec1, point_vec2)_2, ...]\n",
    "    threshold_R: This threshold determines ratio needed between the actual distance and the time delay distance to be recognized as a true nearest neighbor\n",
    "\n",
    "    Return: \n",
    "    A floating point number indicating the number of false nearest neighbors in the dataset. \n",
    "    \"\"\"\n",
    "    tnn, fnn = 0, 0\n",
    "    for i in range(index.shape[0]): \n",
    "        td1, td2 = dataset[i] # time delay vectors \n",
    "        true1, true2 = td1[0], td2[0] # the first value of each time delay vectors are the true voltage value \n",
    "        time_dist = np.linalg.norm(td1 - td2, ord=2) # time delay distance between the two points \n",
    "        actual_dist = np.abs(true1 - true2) # actual distance \n",
    "        dist_ratio = actual_dist / time_dist if time_dist != 0 else 0\n",
    "        print(td1, td2, time_dist)\n",
    "        break\n",
    "        if dist_ratio <= threshold_R: # determine falsehood \n",
    "            fnn += 1\n",
    "        else: \n",
    "            tnn += 1\n",
    "    return fnn / (fnn+tnn)\n",
    "\n",
    "# test the function on the first dataset    \n",
    "fnn_ratio = count_fnn(D_2_index, D_2_data)\n",
    "fnn_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Repeat the search for all D values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the D array and run the ratio calculation algorithm \n",
    "from collections import defaultdict\n",
    "result = defaultdict(float)\n",
    "for d_index in range(len(D_arr)): \n",
    "    dataset = time_delay_datasets[d_index] # get the time delay vectors \n",
    "    min_dist_vector_pairs = generate_min_dist_datapoints(dataset) # generate data pairs \n",
    "    result[D_arr[d_index]] = count_fnn(min_dist_vector_pairs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the result \n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(list(result.keys()), list(result.values()), c='green')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cc42f6639a00a8b355646c6ef947a9e8bbc8e76652a1a42a5022265b8ce8d12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
